{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6977472,
          "sourceType": "datasetVersion",
          "datasetId": 4005256
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NeYDUFCuetrF",
        "7BbnPQiDetrF"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U transformers\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install pandas matplotlib"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:08.348786Z",
          "iopub.execute_input": "2023-12-29T11:09:08.349681Z",
          "iopub.status.idle": "2023-12-29T11:09:44.173932Z",
          "shell.execute_reply.started": "2023-12-29T11:09:08.349653Z",
          "shell.execute_reply": "2023-12-29T11:09:44.172993Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXZK-5PZetq-",
        "outputId": "18e0726e-02fc-496a-ac86-4a6b29c94d57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_to_dataset = \"\"\n",
        "#Per comodità, per capire se stiamo eseguendo su Google Colab o su Kaggle\n",
        "if os.path.exists('/content/'):\n",
        "        path_to_dataset = \"/content/train_v2_drcat_02.csv\"\n",
        "\n",
        "    # Verifica se è presente la cartella \"input\" caratteristica di Kaggle\n",
        "if os.path.exists('/kaggle/input/'):\n",
        "        path_to_dataset = \"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\"\n"
      ],
      "metadata": {
        "id": "xRrfjWzifR75"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(path_to_dataset)\n",
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:44.181422Z",
          "iopub.execute_input": "2023-12-29T11:09:44.181726Z",
          "iopub.status.idle": "2023-12-29T11:09:45.153747Z",
          "shell.execute_reply.started": "2023-12-29T11:09:44.181700Z",
          "shell.execute_reply": "2023-12-29T11:09:45.152945Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gqLG203etrB",
        "outputId": "44b7df61-ae26-4b13-f4ac-8bc0f4c9edba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44868 entries, 0 to 44867\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   text           44868 non-null  object\n",
            " 1   label          44868 non-null  int64 \n",
            " 2   prompt_name    44868 non-null  object\n",
            " 3   source         44868 non-null  object\n",
            " 4   RDizzl3_seven  44868 non-null  bool  \n",
            "dtypes: bool(1), int64(1), object(3)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creazione di train e test"
      ],
      "metadata": {
        "id": "23kNwia6etrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('source',axis = 1)\n",
        "df = df.drop('RDizzl3_seven',axis = 1)\n",
        "data = df\n",
        "data = data.drop('label',axis = 1)\n",
        "data = data.drop('prompt_name',axis = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:45.155949Z",
          "iopub.execute_input": "2023-12-29T11:09:45.156651Z",
          "iopub.status.idle": "2023-12-29T11:09:45.168086Z",
          "shell.execute_reply.started": "2023-12-29T11:09:45.156621Z",
          "shell.execute_reply": "2023-12-29T11:09:45.167219Z"
        },
        "trusted": true,
        "id": "9RiPJQcmetrC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:45.169029Z",
          "iopub.execute_input": "2023-12-29T11:09:45.169288Z",
          "iopub.status.idle": "2023-12-29T11:09:45.178873Z",
          "shell.execute_reply.started": "2023-12-29T11:09:45.169265Z",
          "shell.execute_reply": "2023-12-29T11:09:45.177897Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4fPKvGySetrC",
        "outputId": "357d89be-1718-4f8c-b190-7ab19cf6a8fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text\n",
              "0      Phones\\n\\nModern humans today are always on th...\n",
              "1      This essay will explain if drivers should or s...\n",
              "2      Driving while the use of cellular devices\\n\\nT...\n",
              "3      Phones & Driving\\n\\nDrivers should not be able...\n",
              "4      Cell Phone Operation While Driving\\n\\nThe abil...\n",
              "...                                                  ...\n",
              "44863  Dear Senator,\\n\\nI am writing to you today to ...\n",
              "44864  Dear Senator,\\n\\nI am writing to you today to ...\n",
              "44865  Dear Senator,\\n\\nI am writing to you today to ...\n",
              "44866  Dear Senator,\\n\\nI am writing to you today to ...\n",
              "44867  Dear Senator,\\n\\nI am writing to you today to ...\n",
              "\n",
              "[44868 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97700ab2-802f-4789-ab81-315c3c622355\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This essay will explain if drivers should or s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44863</th>\n",
              "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44864</th>\n",
              "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44865</th>\n",
              "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44866</th>\n",
              "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44867</th>\n",
              "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44868 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97700ab2-802f-4789-ab81-315c3c622355')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97700ab2-802f-4789-ab81-315c3c622355 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97700ab2-802f-4789-ab81-315c3c622355');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-580fbba6-5b8b-4f46-ae48-ea98cd114e68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-580fbba6-5b8b-4f46-ae48-ea98cd114e68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-580fbba6-5b8b-4f46-ae48-ea98cd114e68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning"
      ],
      "metadata": {
        "id": "-GhK4Ca7t_3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Togliamo le stop-words.\n"
      ],
      "metadata": {
        "id": "5mNh-xSrr4DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#import nltk\n",
        "#from nltk.corpus import stopwords\n",
        "#NLTK\n",
        "#nltk.download('stopwords')\n",
        "#stop = set(stopwords.words('english'))\n",
        "\n",
        "#def remove_stop_words_nltk(text):\n",
        "#    words = text.split()\n",
        "#    filtered_words = [word for word in words if word.lower() not in stop]\n",
        "#    return ' '.join(filtered_words)\n",
        "#Alternativa con SpaCy\n",
        "import spacy\n",
        "#loading the english language small model of spacy\n",
        "en = spacy.load('en_core_web_sm')\n",
        "sw_spacy = en.Defaults.stop_words\n",
        "print(sw_spacy)\n",
        "\n",
        "def remove_stop_words_spacy(text):\n",
        "    words = [word for word in text.split() if word.lower() not in sw_spacy]\n",
        "    new_text = \" \".join(words)\n",
        "    return new_text\n",
        "\n",
        "#Alternativa con Gensim\n",
        "#import gensim\n",
        "#from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
        "#print(STOPWORDS)\n",
        "\n",
        "#def remove_stop_words_gensim(text):\n",
        "#  new_text = remove_stopwords(text)\n",
        "#  return new_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3f86D1Z53CN",
        "outputId": "f595d392-6985-4aab-f0bc-4beeddfa9472"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'anything', 'thereby', 'under', 'another', 'hundred', 'myself', 'has', 'twelve', 'still', 'therefore', 'became', '’m', \"'d\", 'otherwise', 'therein', 'yours', 'empty', 'whereby', 'out', 'hers', 'every', 'again', 'fifteen', '‘d', 'many', 'twenty', 'done', 'whereafter', 'latterly', 'back', 'six', 'if', 'n’t', 'whether', 'does', 'what', 'seem', 'whose', 'from', 'they', 'ourselves', 'show', 'each', 'such', 'and', 'down', '‘re', 'eight', 'doing', 'who', 'n‘t', 'moreover', 'somewhere', 'various', 'anyone', 'someone', 'how', 'regarding', 'after', 'rather', 'whole', 'several', 'none', 'do', 'will', 'else', 'really', 'which', 'cannot', 'namely', 'would', 'around', 'was', 'him', 'whence', 'all', 'everywhere', 'together', \"'re\", 'forty', 'thence', 'were', 'further', 'other', 'quite', 'becoming', 'keep', 'too', 'alone', 'side', 'below', 'had', 'us', 'no', 'me', 'anyhow', 'sometimes', 'something', 'until', 'always', 'been', 'whereas', 'i', 'above', 'on', 'off', 'through', 'toward', 'give', 'anyway', 'everything', 'amongst', 'but', 'meanwhile', 'being', 'mostly', 'perhaps', 'sometime', 'am', 'besides', 'only', 'towards', 'less', 'when', '’ll', 'wherein', 'then', 'within', 'as', 'did', 'any', 'wherever', 'whatever', 'neither', 'get', 'thus', 'why', 'beyond', 'behind', 'because', 'of', 'up', 'where', '‘ll', 'among', 'here', 'itself', 'should', 'make', 'hereupon', 'without', 'seeming', 're', 'could', 'hereafter', 'move', 'whither', '’d', 'my', 'least', 'might', 'hereby', 'ten', 'once', 'whom', 'call', 'say', 'nobody', 'seemed', 'five', '’s', 'her', 'about', 'while', 'part', 'top', 'others', 'an', 'may', 'it', 'its', 'thereafter', 'into', 'per', '‘m', 'go', 'whenever', 'former', 'since', 'ca', 'in', 'bottom', 'nevertheless', 'nothing', 'some', 'see', 'over', 'now', 'two', 'these', 'between', 'not', 'yourself', 'or', 'hence', 'just', 'there', 'themselves', 'whereupon', 'first', 'much', 'few', 'via', 'becomes', 'himself', 'he', \"n't\", 'same', 'she', 'nowhere', 'used', 'ours', 'nor', 'with', 'formerly', 'his', 'using', \"'ve\", 'most', 'everyone', 'onto', 'front', 'please', 'next', 'are', 'during', 'this', 'name', \"'m\", 'for', 'even', 'herself', 'made', 'serious', 'whoever', 'however', 'take', 'fifty', '‘ve', 'three', 'last', 'our', 'latter', 'upon', 'herein', 'thru', 'afterwards', 'amount', 'along', 'except', 'full', 'yourselves', 'both', 'yet', 'unless', 'though', 'mine', 'the', 'throughout', 'to', 'so', \"'ll\", '’re', 'sixty', 'very', '‘s', 'those', 'often', 'anywhere', 'more', 'almost', 'must', 'noone', 'them', 'due', 'elsewhere', 'also', 'become', \"'s\", 'nine', 'own', 'never', 'your', 'well', 'can', 'a', 'four', 'have', '’ve', 'by', 'indeed', 'seems', 'thereupon', 'you', 'third', 'beforehand', 'at', 'eleven', 'is', 'their', 'beside', 'somehow', 'put', 'already', 'than', 'that', 'against', 'ever', 'we', 'across', 'enough', 'although', 'be', 'before', 'either', 'one'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ANIS0G3Dt-VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index,row in data.iterrows():\n",
        "  #print(f\"{index} {row}\")\n",
        "  new_string = remove_stop_words_spacy(row['text'])\n",
        "  data.at[index,'text'] = new_string\n",
        "\n",
        "\n",
        "data.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "lzkQ_LGM54HG",
        "outputId": "7d0db9cf-d29c-44df-bfc9-efe85e6adabf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  Phones Modern humans today phone. phone 5 hour..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c96364b-65a7-43ba-a1a5-156aaf9dc32c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phones Modern humans today phone. phone 5 hour...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c96364b-65a7-43ba-a1a5-156aaf9dc32c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c96364b-65a7-43ba-a1a5-156aaf9dc32c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c96364b-65a7-43ba-a1a5-156aaf9dc32c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Togliamo la punteggiatura e i caratteri speciali"
      ],
      "metadata": {
        "id": "YXCMbqFpuKnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation_with_string(text):\n",
        "    new_text = \"\"\n",
        "    for word in text:\n",
        "      for i in range(len(word)):\n",
        "        if word[i] not in string.punctuation:\n",
        "          new_text+=word[i]\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "oq45f335uJJl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index,row in data.iterrows():\n",
        "  #print(f\"{index} {row}\")\n",
        "  new_string = remove_punctuation_with_string(row['text'])\n",
        "  data.at[index,'text'] = new_string\n",
        "\n",
        "\n",
        "data.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "52TfVtaa_klX",
        "outputId": "7d87dfbc-1434-441f-a123-4d96b5878f92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  Phones Modern humans today phone phone 5 hours..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f8a5e75-b02f-44b2-9780-813e2bdf8627\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phones Modern humans today phone phone 5 hours...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f8a5e75-b02f-44b2-9780-813e2bdf8627')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f8a5e75-b02f-44b2-9780-813e2bdf8627 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f8a5e75-b02f-44b2-9780-813e2bdf8627');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some tries"
      ],
      "metadata": {
        "id": "hKKgBPe_PhC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lunghezza_massima = max(len(sequenza.split()) for sequenza in data['text'])\n",
        "\n",
        "print(\"Lunghezza massima delle sequenze:\", lunghezza_massima)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:45.179752Z",
          "iopub.execute_input": "2023-12-29T11:09:45.180030Z",
          "iopub.status.idle": "2023-12-29T11:09:45.927027Z",
          "shell.execute_reply.started": "2023-12-29T11:09:45.180010Z",
          "shell.execute_reply": "2023-12-29T11:09:45.926449Z"
        },
        "trusted": true,
        "id": "DXMfLOYcetrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# Calcola la lunghezza media delle sequenze nel dataset\n",
        "lunghezza_medio = sum(len(sequenza.split()) for sequenza in data['text']) / len(data['text'])\n",
        "lunghezza_medio = math.ceil(lunghezza_medio)\n",
        "print(\"Lunghezza media delle sequenze:\", lunghezza_medio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:45.927702Z",
          "iopub.execute_input": "2023-12-29T11:09:45.927909Z",
          "iopub.status.idle": "2023-12-29T11:09:46.666847Z",
          "shell.execute_reply.started": "2023-12-29T11:09:45.927890Z",
          "shell.execute_reply": "2023-12-29T11:09:46.666165Z"
        },
        "trusted": true,
        "id": "TomqGYtGetrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Calcola la lunghezza delle sequenze\n",
        "lunghezze_sequenze = [len(sequenza.split()) for sequenza in data['text']]\n",
        "\n",
        "# Scegli il percentile desiderato (ad esempio, il 95° percentile)\n",
        "percentile_desiderato = 95\n",
        "\n",
        "# Calcola il valore del percentile\n",
        "lunghezza_percentile = np.percentile(lunghezze_sequenze, percentile_desiderato)\n",
        "\n",
        "lunghezza_percentile =  math.ceil(lunghezza_percentile)\n",
        "\n",
        "print(f\"{percentile_desiderato}° percentile della lunghezza delle sequenze:\", lunghezza_percentile)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:46.667881Z",
          "iopub.execute_input": "2023-12-29T11:09:46.668488Z",
          "iopub.status.idle": "2023-12-29T11:09:47.426519Z",
          "shell.execute_reply.started": "2023-12-29T11:09:46.668459Z",
          "shell.execute_reply": "2023-12-29T11:09:47.425397Z"
        },
        "trusted": true,
        "id": "WmYp_HRjetrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train_test_split"
      ],
      "metadata": {
        "id": "dJgvokrVPklH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Supponiamo che il tuo dataset sia rappresentato da X (feature) e y (etichette)\n",
        "#X_train, X_temp, y_train, y_temp = train_test_split(data['text'], df['label'], test_size=0.2, random_state=42)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:47.428188Z",
          "iopub.execute_input": "2023-12-29T11:09:47.428561Z",
          "iopub.status.idle": "2023-12-29T11:09:47.444374Z",
          "shell.execute_reply.started": "2023-12-29T11:09:47.428532Z",
          "shell.execute_reply": "2023-12-29T11:09:47.443544Z"
        },
        "trusted": true,
        "id": "p96mrDL0etrE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input,val_input,train_label,val_label = train_test_split(data['text'],df['label'])\n"
      ],
      "metadata": {
        "id": "JjPZ58lrDW7d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input.shape,train_label.shape)"
      ],
      "metadata": {
        "id": "uSg0a8wMD95o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bert Tokenizer"
      ],
      "metadata": {
        "id": "5vruSEaqPo0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,TFBertModel,BertConfig,TFBertForSequenceClassification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp_Td0GtEETM",
        "outputId": "42d01a4e-a9b9-432c-912d-c1f287c2b6dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_print = data['text'][0]\n",
        "print(to_print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvrXUtqNEYHL",
        "outputId": "a54da93b-c433-43fd-f224-9170504a5384"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phones Modern humans today phone phone 5 hours day stop All text forward group Chats social media driving bad consequences stuff happens comes phone certain areas United States ban phones class rooms it people phones know certain apps Apps like Facebook Twitter Instagram Snapchat like friend moves away want contact contact posting videos text messages People different ways communicate phone Phones changed generation Driving way around People phones it cause Problems Thats theres thing thats called texting driving Thats important thing remember people think Its stupid matter obey thats way save news accident suicide involve looking theyre going tweet sent injury death mysterious number says Im going kill know live dont know persons contact It makes puzzled start freak out end badly Phones fine use its best way come help problem cant find help always phone you phones day long youre safe come use trouble sure like phone youre middle driving news updated people stupid involves phones safest way best way stay safe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_print_tokenized = tokenizer.tokenize(to_print)\n",
        "print(to_print_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMBaw1h-EyLa",
        "outputId": "2b0c2fde-41da-4d64-ca46-3a6471cf0d64"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['phones', 'modern', 'humans', 'today', 'phone', 'phone', '5', 'hours', 'day', 'stop', 'all', 'text', 'forward', 'group', 'chat', '##s', 'social', 'media', 'driving', 'bad', 'consequences', 'stuff', 'happens', 'comes', 'phone', 'certain', 'areas', 'united', 'states', 'ban', 'phones', 'class', 'rooms', 'it', 'people', 'phones', 'know', 'certain', 'apps', 'apps', 'like', 'facebook', 'twitter', 'ins', '##tagram', 'snap', '##cha', '##t', 'like', 'friend', 'moves', 'away', 'want', 'contact', 'contact', 'posting', 'videos', 'text', 'messages', 'people', 'different', 'ways', 'communicate', 'phone', 'phones', 'changed', 'generation', 'driving', 'way', 'around', 'people', 'phones', 'it', 'cause', 'problems', 'that', '##s', 'there', '##s', 'thing', 'that', '##s', 'called', 'text', '##ing', 'driving', 'that', '##s', 'important', 'thing', 'remember', 'people', 'think', 'its', 'stupid', 'matter', 'obey', 'that', '##s', 'way', 'save', 'news', 'accident', 'suicide', 'involve', 'looking', 'they', '##re', 'going', 't', '##wee', '##t', 'sent', 'injury', 'death', 'mysterious', 'number', 'says', 'im', 'going', 'kill', 'know', 'live', 'don', '##t', 'know', 'persons', 'contact', 'it', 'makes', 'puzzled', 'start', 'freak', 'out', 'end', 'badly', 'phones', 'fine', 'use', 'its', 'best', 'way', 'come', 'help', 'problem', 'can', '##t', 'find', 'help', 'always', 'phone', 'you', 'phones', 'day', 'long', 'your', '##e', 'safe', 'come', 'use', 'trouble', 'sure', 'like', 'phone', 'your', '##e', 'middle', 'driving', 'news', 'updated', 'people', 'stupid', 'involves', 'phones', 'safe', '##st', 'way', 'best', 'way', 'stay', 'safe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Token to ids',tokenizer.convert_tokens_to_ids(tokenizer.tokenize(to_print)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUyQ0tqmE5K7",
        "outputId": "9a0509ca-39d0-4e25-99c3-a3b97eb427f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token to ids [11640, 2715, 4286, 2651, 3042, 3042, 1019, 2847, 2154, 2644, 2035, 3793, 2830, 2177, 11834, 2015, 2591, 2865, 4439, 2919, 8465, 4933, 6433, 3310, 3042, 3056, 2752, 2142, 2163, 7221, 11640, 2465, 4734, 2009, 2111, 11640, 2113, 3056, 18726, 18726, 2066, 9130, 10474, 16021, 23091, 10245, 7507, 2102, 2066, 2767, 5829, 2185, 2215, 3967, 3967, 14739, 6876, 3793, 7696, 2111, 2367, 3971, 10639, 3042, 11640, 2904, 4245, 4439, 2126, 2105, 2111, 11640, 2009, 3426, 3471, 2008, 2015, 2045, 2015, 2518, 2008, 2015, 2170, 3793, 2075, 4439, 2008, 2015, 2590, 2518, 3342, 2111, 2228, 2049, 5236, 3043, 15470, 2008, 2015, 2126, 3828, 2739, 4926, 5920, 9125, 2559, 2027, 2890, 2183, 1056, 28394, 2102, 2741, 4544, 2331, 8075, 2193, 2758, 10047, 2183, 3102, 2113, 2444, 2123, 2102, 2113, 5381, 3967, 2009, 3084, 14909, 2707, 11576, 2041, 2203, 6649, 11640, 2986, 2224, 2049, 2190, 2126, 2272, 2393, 3291, 2064, 2102, 2424, 2393, 2467, 3042, 2017, 11640, 2154, 2146, 2115, 2063, 3647, 2272, 2224, 4390, 2469, 2066, 3042, 2115, 2063, 2690, 4439, 2739, 7172, 2111, 5236, 7336, 11640, 3647, 3367, 2126, 2190, 2126, 2994, 3647]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for d in data['text']:\n",
        "  input_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(d))\n",
        "  max_len = max(max_len,len(input_ids))\n",
        "print(max_len)\n",
        "max_len=512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "E9oXw3YVFiA3",
        "outputId": "af59920f-751a-478f-e93d-4b952896639a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-73c4d8390da7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             for token in self.basic_tokenizer.tokenize(\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msplit_special_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# union() returns a new set by concatenating the two sets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mnever_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnever_split\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# This was added on November 1st, 2018 for the multilingual and Chinese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_clean_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xFFFD\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_is_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_is_whitespace\u001b[0;34m(char)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;31m# \\t, \\n, and \\r are technically control characters but we treat them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# as whitespace since they are generally considered as such.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=512"
      ],
      "metadata": {
        "id": "dGaleftAcMlM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inputs_for_bert(data,max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  i = 0\n",
        "  for d in data:\n",
        "    if(i<3):\n",
        "      print(\"Data\",d)\n",
        "      print()\n",
        "    encoded_dict = tokenizer.encode_plus(d,add_special_tokens=True,max_length=max_len,truncation=True,return_attention_mask = True)\n",
        "    if(i<3):\n",
        "      print(\"dict\",encoded_dict['input_ids'])\n",
        "      print()\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    i=i+1\n",
        "  input_ids = tf.convert_to_tensor(input_ids)\n",
        "  attention_masks = tf.convert_to_tensor(attention_masks)\n",
        "  return input_ids,attention_masks"
      ],
      "metadata": {
        "id": "hGKdIO1SGQDG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Tokenize the sentence.\n",
        "(2) Prepend the ‘[CLS]’ token to the start.\n",
        "(3) Append the ‘[SEP]’ token to the end.\n",
        "(4) Map tokens to their IDs.\n",
        "(5) Pad or truncate the sentence to ‘max_length’\n",
        "(6) Create attention masks for ‘[PAD]’ tokens."
      ],
      "metadata": {
        "id": "vYjsABKfFafG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids2 = []\n",
        "attention_masks2 = []\n",
        "for i in range(len(val_input)):\n",
        "  print(f'{val_input[0]}')\n",
        "  encoded_dict = tokenizer.encode_plus(val_input[i],add_special_tokens=True,padding='max_length',return_attention_mask = True)\n",
        "  input_ids2.append(encoded_dict['input_ids'])\n",
        "  attention_masks2.append(encoded_dict['attention_mask'])\n",
        "  if i==1:\n",
        "    break\n",
        "input_ids2 = tf.convert_to_tensor(input_ids2)\n",
        "attention_masks2 = tf.convert_to_tensor(attention_masks2)"
      ],
      "metadata": {
        "id": "8aLJX5fnM_Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inp,train_mask = build_inputs_for_bert(train_input,max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLg-hQCVFYod",
        "outputId": "4f6198d6-6aee-491e-d1dc-94d25561905a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data The Power Imagination Imagination powerful tool ability shape world ways thought possible driving force innovation progress it technological advancements enjoy today compelling arguments importance imagination fact led greatest inventions human history Wright Brothers invention airplane discovery penicillin power imagination allowed overcome seemingly insurmountable challenges push boundaries possible Imagination plays crucial role personal lives allows envision better future loved ones work achieving goals use imagination visualize success likely action reality Furthermore imagination power heal bring joy lives feeling stressed use imagination transport happier place its tropical beach peaceful forest help feel relaxed centered provide temporary escape problems conclusion imagination powerful tool ability shape world countless ways driving force innovation progress personal growth essential human experience So lets embrace imagination use create brighter beautiful future generations come\n",
            "\n",
            "dict [101, 1996, 2373, 9647, 9647, 3928, 6994, 3754, 4338, 2088, 3971, 2245, 2825, 4439, 2486, 8144, 5082, 2009, 10660, 12607, 2015, 5959, 2651, 17075, 9918, 5197, 9647, 2755, 2419, 4602, 21644, 2529, 2381, 6119, 3428, 11028, 13297, 5456, 7279, 28775, 21202, 2373, 9647, 3039, 9462, 9428, 16021, 3126, 20048, 3085, 7860, 5245, 7372, 2825, 9647, 3248, 10232, 2535, 3167, 3268, 4473, 4372, 17084, 2488, 2925, 3866, 3924, 2147, 10910, 3289, 2224, 9647, 5107, 4697, 3112, 3497, 2895, 4507, 7297, 9647, 2373, 11005, 3288, 6569, 3268, 3110, 13233, 2224, 9647, 3665, 19366, 2173, 2049, 5133, 3509, 9379, 3224, 2393, 2514, 8363, 8857, 3073, 5741, 4019, 3471, 7091, 9647, 3928, 6994, 3754, 4338, 2088, 14518, 3971, 4439, 2486, 8144, 5082, 3167, 3930, 6827, 2529, 3325, 2061, 11082, 9979, 9647, 2224, 3443, 16176, 3376, 2925, 8213, 2272, 102]\n",
            "\n",
            "Data learning home help person learning school incredible  example school professors help students learn instructing knowledge stick craniums Students interact classmates helps learn way better Furthermore teachers easier school students learn teaching information faces while online students question work website Students wouldnt gain learning home school experience meet new people Youll obtain learning experience school instance students learn school teacher right them teaching lesson them Students opportunity ask teacher questions theyre having trouble topic confused about hand human beings learn home its harder ask questions video chat fail teacher able hear loud disturbances classroom Ultimately shows having learning experience way helpful learning stupid video chat crash lesson Meeting new people way enjoyable  example kids lot excitement theyre school theyre talking people making new friends Also friend school long term friend life makes life amazing  Similarly friend second grade best friends hang today hand learning home cant meet new friends its boring as watching paint dry making new friends school cooler tired bored home learning home easier traveling school everyday students wouldnt experience classroom learning teacher them classmates talk to students want home able talk teacher face face Students wouldnt meet new people cause students bored  then task wouldnt feel like learning example student question theyre learning video chat crash student feel annoyed time teacher instruct student summary Learning home beneficial obtaining important information heads school Students wouldnt gain learning home school experience meet new people school students learn better learning teachers giving instruction them electronic device students ask important questions teachers Having experience way important students feel learning environment interact peers classroom conclusion taking online classes home going school learning environment fellow classmates way extraordinary beneficial learning Listen essay school learn greatest teachers meet friend future fantastic \n",
            "\n",
            "dict [101, 4083, 2188, 2393, 2711, 4083, 2082, 9788, 2742, 2082, 12655, 2393, 2493, 4553, 16021, 26310, 3716, 6293, 13675, 7088, 18163, 2493, 11835, 19846, 7126, 4553, 2126, 2488, 7297, 5089, 6082, 2082, 2493, 4553, 4252, 2592, 5344, 2096, 3784, 2493, 3160, 2147, 4037, 2493, 2876, 2102, 5114, 4083, 2188, 2082, 3325, 3113, 2047, 2111, 2017, 3363, 6855, 4083, 3325, 2082, 6013, 2493, 4553, 2082, 3836, 2157, 2068, 4252, 10800, 2068, 2493, 4495, 3198, 3836, 3980, 2027, 2890, 2383, 4390, 8476, 5457, 2055, 2192, 2529, 9552, 4553, 2188, 2049, 6211, 3198, 3980, 2678, 11834, 8246, 3836, 2583, 2963, 5189, 24535, 9823, 4821, 3065, 2383, 4083, 3325, 2126, 14044, 4083, 5236, 2678, 11834, 5823, 10800, 3116, 2047, 2111, 2126, 22249, 2742, 4268, 2843, 8277, 2027, 2890, 2082, 2027, 2890, 3331, 2111, 2437, 2047, 2814, 2036, 2767, 2082, 2146, 2744, 2767, 2166, 3084, 2166, 6429, 6660, 2767, 2117, 3694, 2190, 2814, 6865, 2651, 2192, 4083, 2188, 2064, 2102, 3113, 2047, 2814, 2049, 11771, 2004, 3666, 6773, 4318, 2437, 2047, 2814, 2082, 14976, 5458, 11471, 2188, 4083, 2188, 6082, 7118, 2082, 10126, 2493, 2876, 2102, 3325, 9823, 4083, 3836, 2068, 19846, 2831, 2000, 2493, 2215, 2188, 2583, 2831, 3836, 2227, 2227, 2493, 2876, 2102, 3113, 2047, 2111, 3426, 2493, 11471, 2059, 4708, 2876, 2102, 2514, 2066, 4083, 2742, 3076, 3160, 2027, 2890, 4083, 2678, 11834, 5823, 3076, 2514, 11654, 2051, 3836, 16021, 18300, 3076, 12654, 4083, 2188, 15189, 11381, 2590, 2592, 4641, 2082, 2493, 2876, 2102, 5114, 4083, 2188, 2082, 3325, 3113, 2047, 2111, 2082, 2493, 4553, 2488, 4083, 5089, 3228, 7899, 2068, 4816, 5080, 2493, 3198, 2590, 3980, 5089, 2383, 3325, 2126, 2590, 2493, 2514, 4083, 4044, 11835, 12746, 9823, 7091, 2635, 3784, 4280, 2188, 2183, 2082, 4083, 4044, 3507, 19846, 2126, 9313, 15189, 4083, 4952, 9491, 2082, 4553, 4602, 5089, 3113, 2767, 2925, 10392, 102]\n",
            "\n",
            "Data Its important seek opinions making decision provide valuable insights experiences help guide right direction youre considering new hobby career change purchase seeking advice help avoid costly mistakes informed decisions example youre thinking buying new car its good idea talk owned model youre interested in provide firsthand information cars reliability performance potential issues aware of help informed decision avoid wasting money car best fit needs Similarly youre considering starting new business its important seek advice experienced entrepreneurs provide valuable insights industry help identify potential challenges opportunities offer guidance navigate complex world entrepreneurship Its important remember advice created equal seeking advice its important consider source expertise subject matter its important open different perspectives its important discerning critical evaluating advice receive conclusion seeking opinions important making informed decisions youre considering new purchase career change major life decision seeking advice help avoid costly mistakes best decision needs\n",
            "\n",
            "dict [101, 2049, 2590, 6148, 10740, 2437, 3247, 3073, 7070, 20062, 6322, 2393, 5009, 2157, 3257, 2115, 2063, 6195, 2047, 17792, 2476, 2689, 5309, 6224, 6040, 2393, 4468, 17047, 12051, 6727, 6567, 2742, 2115, 2063, 3241, 9343, 2047, 2482, 2049, 2204, 2801, 2831, 3079, 2944, 2115, 2063, 4699, 1999, 3073, 2034, 11774, 2592, 3765, 15258, 2836, 4022, 3314, 5204, 1997, 2393, 6727, 3247, 4468, 18313, 2769, 2482, 2190, 4906, 3791, 6660, 2115, 2063, 6195, 3225, 2047, 2449, 2049, 2590, 6148, 6040, 5281, 17633, 3073, 7070, 20062, 3068, 2393, 6709, 4022, 7860, 6695, 3749, 8606, 22149, 3375, 2088, 20213, 2049, 2590, 3342, 6040, 2580, 5020, 6224, 6040, 2049, 2590, 5136, 3120, 11532, 3395, 3043, 2049, 2590, 2330, 2367, 15251, 2049, 2590, 5860, 11795, 2075, 4187, 23208, 6040, 4374, 7091, 6224, 10740, 2590, 2437, 6727, 6567, 2115, 2063, 6195, 2047, 5309, 2476, 2689, 2350, 2166, 3247, 6224, 6040, 2393, 4468, 17047, 12051, 2190, 3247, 3791, 102]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_inp,val_mask = build_inputs_for_bert(val_input,max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qeI052fQ3_Y",
        "outputId": "a2864e4a-284f-4bab-c2a8-bc5dd746a497"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Hey there So know meet new know youre gonna BFFs not Yeah impressions real thing man totally break relationship Like think it meet someone youre like judging based look talk say dont like see well its kinda hard forget it Its like brain like Hmm person kinda weird dont wanna hang them dont thing falls apart But hand good impression its like rainbows unicorns Youre like Oh gosh person cool wanna hang time do its like best thing ever mean think it met like super nice friendly found actually kinda mean something Its like whoa impressions important man tell lot person its people either Like think saw classroom like it think was like super lame mean personally think its pretty cool Im sure people agree Anyway point is impressions big deal break relationships affect feel place thing So time meet new walk new space try aware impression know change everything Oh thing\n",
            "\n",
            "dict [101, 4931, 2045, 2061, 2113, 3113, 2047, 2113, 2115, 2063, 6069, 28939, 10343, 2025, 3398, 19221, 2613, 2518, 2158, 6135, 3338, 3276, 2066, 2228, 2009, 3113, 2619, 2115, 2063, 2066, 13325, 2241, 2298, 2831, 2360, 2123, 2102, 2066, 2156, 2092, 2049, 17704, 2524, 5293, 2009, 2049, 2066, 4167, 2066, 17012, 2711, 17704, 6881, 2123, 2102, 10587, 6865, 2068, 2123, 2102, 2518, 4212, 4237, 2021, 2192, 2204, 8605, 2049, 2066, 10098, 2015, 21830, 2015, 2115, 2063, 2066, 2821, 2175, 4095, 2711, 4658, 10587, 6865, 2051, 2079, 2049, 2066, 2190, 2518, 2412, 2812, 2228, 2009, 2777, 2066, 3565, 3835, 5379, 2179, 2941, 17704, 2812, 2242, 2049, 2066, 23281, 19221, 2590, 2158, 2425, 2843, 2711, 2049, 2111, 2593, 2066, 2228, 2387, 9823, 2066, 2009, 2228, 2001, 2066, 3565, 20342, 2812, 7714, 2228, 2049, 3492, 4658, 10047, 2469, 2111, 5993, 4312, 2391, 2003, 19221, 2502, 3066, 3338, 6550, 7461, 2514, 2173, 2518, 2061, 2051, 3113, 2047, 3328, 2047, 2686, 3046, 5204, 8605, 2113, 2689, 2673, 2821, 2518, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Data design students entire project scheme actually learning it Students tend better learn projects chance creative assigned task Instead researching teacher designed them example design project students topic book supposed read summer Thats showing student learned shows able follow instructions given teacher student topic learn summer let plan project ability teach actually learn increase Also letting design project variety instead project type student Different projects student chance teacher pinpoint students learned ones didnt makes easier grade offer help ones didnt well However students wont need help chance creative Creativity big help improving learning abilities students chance spark inside drive wanna time understand fun designing project topic teachers designs projects turned bland maybe turned all conclusion freedom way learned summer chance learned way planned them\n",
            "\n",
            "dict [101, 2640, 2493, 2972, 2622, 5679, 2941, 4083, 2009, 2493, 7166, 2488, 4553, 3934, 3382, 5541, 4137, 4708, 2612, 20059, 3836, 2881, 2068, 2742, 2640, 2622, 2493, 8476, 2338, 4011, 3191, 2621, 2008, 2015, 4760, 3076, 4342, 3065, 2583, 3582, 8128, 2445, 3836, 3076, 8476, 4553, 2621, 2292, 2933, 2622, 3754, 6570, 2941, 4553, 3623, 2036, 5599, 2640, 2622, 3528, 2612, 2622, 2828, 3076, 2367, 3934, 3076, 3382, 3836, 9231, 8400, 2493, 4342, 3924, 2134, 2102, 3084, 6082, 3694, 3749, 2393, 3924, 2134, 2102, 2092, 2174, 2493, 2180, 2102, 2342, 2393, 3382, 5541, 14842, 2502, 2393, 9229, 4083, 7590, 2493, 3382, 12125, 2503, 3298, 10587, 2051, 3305, 4569, 12697, 2622, 8476, 5089, 5617, 3934, 2357, 20857, 2672, 2357, 2035, 7091, 4071, 2126, 4342, 2621, 3382, 4342, 2126, 3740, 2068, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Data Development Driverless Cars driverless cars present benefits developing new technology raises safety ethical concerns adequately addressed Details article Driverless Cars Coming help illustrate sides argument Proponents claim driverless cars reduce traffic accidents computers distracted tired impaired like human drivers However article notes vehicles tested traffic conditions guarantee safety Automated systems malfunction difficulty handling unusual situations possibly resulting accidents Furthermore determining bears responsibility event crash involving autonomous vehicle remains unclear Privacy issues arise driverless cars constantly tracking passengers movements storing vast amounts personal data article discusses information potentially hacked abused loss privacy outweigh benefits computerdriven convenience driverless cars day improve mobility elderly disabled achieve higher road capacities curb greenhouse gas emissions cited article technology prove introducing new safety ethical legal risks research needed properly address liability cybersecurity complex questions letting autonomous vehicles operate human drivers public roads Overall technology shows promise developers satisfactorily solve issues better protect passengers pedestrians personal privacy negatives outweigh positives making widespread adoption driverless cars inadvisable study regulation prudent supporting development new transportation method\n",
            "\n",
            "dict [101, 2458, 4062, 3238, 3765, 4062, 3238, 3765, 2556, 6666, 4975, 2047, 2974, 13275, 3808, 12962, 5936, 23613, 8280, 4751, 3720, 4062, 3238, 3765, 2746, 2393, 19141, 3903, 6685, 20401, 4366, 4062, 3238, 3765, 5547, 4026, 13436, 7588, 11116, 5458, 18234, 2066, 2529, 6853, 2174, 3720, 3964, 4683, 7718, 4026, 3785, 11302, 3808, 12978, 3001, 15451, 11263, 27989, 7669, 8304, 5866, 8146, 4298, 4525, 13436, 7297, 12515, 6468, 5368, 2724, 5823, 5994, 8392, 4316, 3464, 10599, 9394, 3314, 13368, 4062, 3238, 3765, 7887, 9651, 5467, 5750, 23977, 6565, 8310, 3167, 2951, 3720, 15841, 2592, 9280, 28719, 16999, 3279, 9394, 2041, 27204, 2232, 6666, 3274, 23663, 2078, 15106, 4062, 3238, 3765, 2154, 5335, 12969, 9750, 9776, 6162, 3020, 2346, 21157, 13730, 16635, 3806, 11768, 6563, 3720, 2974, 6011, 10449, 2047, 3808, 12962, 3423, 10831, 2470, 2734, 7919, 4769, 14000, 16941, 3366, 10841, 15780, 3375, 3980, 5599, 8392, 4683, 5452, 2529, 6853, 2270, 4925, 3452, 2974, 3065, 4872, 9797, 2938, 2483, 7011, 16761, 6588, 9611, 3314, 2488, 4047, 5467, 24946, 3167, 9394, 4997, 2015, 2041, 27204, 2232, 3893, 2015, 2437, 6923, 9886, 4062, 3238, 3765, 27118, 2094, 11365, 3085, 2817, 7816, 10975, 12672, 3372, 4637, 2458, 2047, 5193, 4118, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = tf.convert_to_tensor(train_label)"
      ],
      "metadata": {
        "id": "8SRW1gt9Q6Pm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_label = tf.convert_to_tensor(val_label)"
      ],
      "metadata": {
        "id": "5-5rsEuYQ6Mr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_input_shape\",train_inp.shape)\n",
        "print(\"train_mask_shape\",train_mask.shape)\n",
        "print(\"val_input_shape\",val_inp.shape)\n",
        "print(\"val_mask_shape\",val_mask.shape)\n",
        "print(\"train_label_shape\",train_label.shape)\n",
        "print(\"val_label_shape\",val_label.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CskX12WlUma4",
        "outputId": "b8529a10-546f-4835-a079-0998bd18cda7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_input_shape (33651, 1733)\n",
            "train_mask_shape (33651, 1733)\n",
            "val_input_shape (11217, 1733)\n",
            "val_mask_shape (11217, 1733)\n",
            "train_label_shape (33651,)\n",
            "val_label_shape (11217,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5djmdkG6aLdf",
        "outputId": "ac622485-dfe1-4f99-a67b-a5ee19c84fe7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m636.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "Successfully installed tensorflow-2.15.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2,ignore_mismatched_sizes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6btdKGsUhC9",
        "outputId": "28a1550d-939c-45ba-808d-5790f8eae3d4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "log_dir = \"/content/log\"\n",
        "model_save_path=\"/content/log/bert_model.h5\"\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
        "print(\"Summary\",bert_model.summary())\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) #BinaryCrossEntropy\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
        "bert_model.compile(loss=loss,optimizer=optimizer,metrics=[metric])\n",
        "\n",
        "#bert_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U31HfC9XVOP8",
        "outputId": "8f472d29-432f-4ca6-b2de-6d7bf5ff4c51"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       multiple                  0         \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  1538      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109483778 (417.65 MB)\n",
            "Trainable params: 109483778 (417.65 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Summary None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = bert_model.fit([train_inp,train_mask],train_label,batch_size=32,epochs=4,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bv3rDJd5WbiL",
        "outputId": "c99de7bf-d452-47a4-f131-fcd7d5ae9e03"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-9c0d7e7a17a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification_6/bert/embeddings/Gather_1 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-42-9c0d7e7a17a6>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1641, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1569, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 780, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 215, in call\n\nindices[0,1519] = 1519 is not in [0, 512)\n\t [[{{node tf_bert_for_sequence_classification_6/bert/embeddings/Gather_1}}]] [Op:__inference_train_function_146180]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text encoder\n"
      ],
      "metadata": {
        "id": "-Db7pGgMetrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VOCAB_SIZE = 1000 #Parametro da sistemare\n",
        "\n",
        "#encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE) #output_sequence_length=50 in alternativa ad input_length\n",
        "#encoder.adapt(X_train.values.flatten())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:47.452054Z",
          "iopub.execute_input": "2023-12-29T11:09:47.452324Z",
          "iopub.status.idle": "2023-12-29T11:09:50.899124Z",
          "shell.execute_reply.started": "2023-12-29T11:09:47.452304Z",
          "shell.execute_reply": "2023-12-29T11:09:50.898253Z"
        },
        "trusted": true,
        "id": "BAv5ZJWtetrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Controlliamo se l'encoder funziona"
      ],
      "metadata": {
        "id": "ydqKjTXAetrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#vocab = np.array(encoder.get_vocabulary())\n",
        "#vocab[:20]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:50.937436Z",
          "iopub.execute_input": "2023-12-29T11:09:50.937720Z",
          "iopub.status.idle": "2023-12-29T11:09:50.949914Z",
          "shell.execute_reply.started": "2023-12-29T11:09:50.937699Z",
          "shell.execute_reply": "2023-12-29T11:09:50.948989Z"
        },
        "trusted": true,
        "id": "dJZZ9vvcetrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applichiamo il Padding (VEDERE MEGLIO COME FARE QUESTA COSA)\n"
      ],
      "metadata": {
        "id": "NeYDUFCuetrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#X_train = pad_sequences(X_train, padding='post', maxlen=100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:50.950882Z",
          "iopub.execute_input": "2023-12-29T11:09:50.951105Z",
          "iopub.status.idle": "2023-12-29T11:09:50.957866Z",
          "shell.execute_reply.started": "2023-12-29T11:09:50.951086Z",
          "shell.execute_reply": "2023-12-29T11:09:50.956986Z"
        },
        "trusted": true,
        "id": "sJlHIqwKetrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:50.958909Z",
          "iopub.execute_input": "2023-12-29T11:09:50.959146Z",
          "iopub.status.idle": "2023-12-29T11:09:50.968274Z",
          "shell.execute_reply.started": "2023-12-29T11:09:50.959120Z",
          "shell.execute_reply": "2023-12-29T11:09:50.967249Z"
        },
        "trusted": true,
        "id": "a73gG1CaetrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creiamo un embedding"
      ],
      "metadata": {
        "id": "7BbnPQiDetrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5) #SERVE SOLO DA ESEMPIO IL VERO PADDING è NELLA RETE"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:50.969559Z",
          "iopub.execute_input": "2023-12-29T11:09:50.970089Z",
          "iopub.status.idle": "2023-12-29T11:09:50.980276Z",
          "shell.execute_reply.started": "2023-12-29T11:09:50.970063Z",
          "shell.execute_reply": "2023-12-29T11:09:50.979638Z"
        },
        "trusted": true,
        "id": "Ph9hvelietrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST PER VEDERE SE FUNZIONA IL LAYER EMBEDDING #SERVE SOLO DA ESEMPIO IL VERO PADDING è NELLA RETE\n",
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:50.981232Z",
          "iopub.execute_input": "2023-12-29T11:09:50.981791Z",
          "iopub.status.idle": "2023-12-29T11:09:50.996816Z",
          "shell.execute_reply.started": "2023-12-29T11:09:50.981766Z",
          "shell.execute_reply": "2023-12-29T11:09:50.995738Z"
        },
        "trusted": true,
        "id": "x96fvPQfetrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creazione modello"
      ],
      "metadata": {
        "id": "j9kbrh4LetrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = tf.keras.Sequential([\n",
        "#    encoder, #TextVectorization\n",
        "#    tf.keras.layers.Embedding( #Embedding\n",
        "#        #gestire anche dimensione input e output\n",
        "#        input_dim=len(encoder.get_vocabulary()),\n",
        "#        output_dim=3,\n",
        "#        # aggiungere input_length  =  lunghezza massima o come media o come percentile 95%\n",
        "#        input_length = lunghezza_massima,\n",
        "#        mask_zero=True),\n",
        " #   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),#\n",
        "#    tf.keras.layers.Dense(64, activation='relu'),\n",
        "#    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:10:29.619136Z",
          "iopub.execute_input": "2023-12-29T11:10:29.619461Z",
          "iopub.status.idle": "2023-12-29T11:10:31.095784Z",
          "shell.execute_reply.started": "2023-12-29T11:10:29.619437Z",
          "shell.execute_reply": "2023-12-29T11:10:31.094899Z"
        },
        "trusted": true,
        "id": "OWH73XTgetrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()"
      ],
      "metadata": {
        "id": "MeNSrOXx9DcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:10:36.025610Z",
          "iopub.execute_input": "2023-12-29T11:10:36.026110Z",
          "iopub.status.idle": "2023-12-29T11:10:36.036301Z",
          "shell.execute_reply.started": "2023-12-29T11:10:36.026084Z",
          "shell.execute_reply": "2023-12-29T11:10:36.035339Z"
        },
        "trusted": true,
        "id": "lavgcSksetrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:10:39.393183Z",
          "iopub.execute_input": "2023-12-29T11:10:39.393512Z",
          "iopub.status.idle": "2023-12-29T11:21:09.542778Z",
          "shell.execute_reply.started": "2023-12-29T11:10:39.393473Z",
          "shell.execute_reply": "2023-12-29T11:21:09.541538Z"
        },
        "trusted": true,
        "id": "Ef5YGJGGetrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:51.013235Z",
          "iopub.status.idle": "2023-12-29T11:09:51.013890Z",
          "shell.execute_reply.started": "2023-12-29T11:09:51.013697Z",
          "shell.execute_reply": "2023-12-29T11:09:51.013717Z"
        },
        "trusted": true,
        "id": "LTOsWRZ5etrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "# Stampa il classification report e l'accuracy score\n",
        "report = classification_report(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(report)\n",
        "print(\"****\")\n",
        "print(accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3F18Kxjz6wYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report)\n",
        "print(\"****\")\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "RSXlJg2XAPNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:51.014930Z",
          "iopub.status.idle": "2023-12-29T11:09:51.015862Z",
          "shell.execute_reply.started": "2023-12-29T11:09:51.015654Z",
          "shell.execute_reply": "2023-12-29T11:09:51.015679Z"
        },
        "trusted": true,
        "id": "AXUWGCVketrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:51.016768Z",
          "iopub.status.idle": "2023-12-29T11:09:51.017288Z",
          "shell.execute_reply.started": "2023-12-29T11:09:51.017153Z",
          "shell.execute_reply": "2023-12-29T11:09:51.017168Z"
        },
        "trusted": true,
        "id": "zq9IdM9PetrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in X_test :\n",
        "    predictions = model.predict(np.array([key]))\n",
        "    print(predictions)\n",
        "    break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:51.017999Z",
          "iopub.status.idle": "2023-12-29T11:09:51.018379Z",
          "shell.execute_reply.started": "2023-12-29T11:09:51.018247Z",
          "shell.execute_reply": "2023-12-29T11:09:51.018260Z"
        },
        "trusted": true,
        "id": "jZ6mrcohetrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in y_test :\n",
        "    print(key)\n",
        "    break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-29T11:09:51.019150Z",
          "iopub.status.idle": "2023-12-29T11:09:51.019426Z",
          "shell.execute_reply.started": "2023-12-29T11:09:51.019290Z",
          "shell.execute_reply": "2023-12-29T11:09:51.019304Z"
        },
        "trusted": true,
        "id": "OUYStQBNetrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}